{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Naive_Bayes Algorithm in all the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title: Iris Plants Database\n",
      "\tUpdated Sept 21 by C.Blake - Added discrepency information\n",
      "\n",
      "2. Sources:\n",
      "     (a) Creator: R.A. Fisher\n",
      "     (b) Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "     (c) Date: July, 1988\n",
      "\n",
      "3. Past Usage:\n",
      "   - Publications: too many to mention!!!  Here are a few.\n",
      "   1. Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "      Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions\n",
      "      to Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   2. Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "      (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   3. Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "      Structure and Classification Rule for Recognition in Partially Exposed\n",
      "      Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "      Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "      -- Results:\n",
      "         -- very low misclassification rates (0% for the setosa class)\n",
      "   4. Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE \n",
      "      Transactions on Information Theory, May 1972, 431-433.\n",
      "      -- Results:\n",
      "         -- very low misclassification rates again\n",
      "   5. See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al's AUTOCLASS II\n",
      "      conceptual clustering system finds 3 classes in the data.\n",
      "\n",
      "4. Relevant Information:\n",
      "   --- This is perhaps the best known database to be found in the pattern\n",
      "       recognition literature.  Fisher's paper is a classic in the field\n",
      "       and is referenced frequently to this day.  (See Duda & Hart, for\n",
      "       example.)  The data set contains 3 classes of 50 instances each,\n",
      "       where each class refers to a type of iris plant.  One class is\n",
      "       linearly separable from the other 2; the latter are NOT linearly\n",
      "       separable from each other.\n",
      "   --- Predicted attribute: class of iris plant.\n",
      "   --- This is an exceedingly simple domain.\n",
      "   --- This data differs from the data presented in Fishers article\n",
      "\t(identified by Steve Chadwick,  spchadwick@espeedaz.net )\n",
      "\tThe 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\"\n",
      "\twhere the error is in the fourth feature.\n",
      "\tThe 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\"\n",
      "\twhere the errors are in the second and third features.  \n",
      "\n",
      "5. Number of Instances: 150 (50 in each of three classes)\n",
      "\n",
      "6. Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "\n",
      "7. Attribute Information:\n",
      "   1. sepal length in cm\n",
      "   2. sepal width in cm\n",
      "   3. petal length in cm\n",
      "   4. petal width in cm\n",
      "   5. class: \n",
      "      -- Iris Setosa\n",
      "      -- Iris Versicolour\n",
      "      -- Iris Virginica\n",
      "\n",
      "8. Missing Attribute Values: None\n",
      "\n",
      "Summary Statistics:\n",
      "\t         Min  Max   Mean    SD   Class Correlation\n",
      "   sepal length: 4.3  7.9   5.84  0.83    0.7826   \n",
      "    sepal width: 2.0  4.4   3.05  0.43   -0.4194\n",
      "   petal length: 1.0  6.9   3.76  1.76    0.9490  (high!)\n",
      "    petal width: 0.1  2.5   1.20  0.76    0.9565  (high!)\n",
      "\n",
      "9. Class Distribution: 33.3% for each of 3 classes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/iris.names\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/iris.data\", names=col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit, ShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:, 0:4]\n",
    "labels = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "label_encoder.fit(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label_encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9333333333333333\n",
      "Accuracy Score of Test Set: 0.9\n",
      "F1 Score of Test Set: 0.899248120300752\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.75      1.00      0.86         9\n",
      "           2       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.92      0.91      0.90        30\n",
      "weighted avg       0.93      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, MultiNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_MNB = MultiNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_MNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_MNB, average='weighted')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_MNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BernNB = BernoulliNB()\n",
    "BernNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_BNB = BernNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.3416666666666667\n",
      "Accuracy Score of Test Set: 0.3\n",
      "F1 Score of Test Set: 0.3\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.30      1.00      0.46         9\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.10      0.33      0.15        30\n",
      "weighted avg       0.09      0.30      0.14        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, BernNB.predict(X_train))}\")\n",
    "\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_BNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_BNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_BNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussNB = GaussianNB()\n",
    "GaussNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GNB = BernNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.975\n",
      "Accuracy Score of Test Set: 0.3\n",
      "F1 Score of Test Set: 0.3\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.30      1.00      0.46         9\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.10      0.33      0.15        30\n",
      "weighted avg       0.09      0.30      0.14        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, GaussNB.predict(X_train))}\")\n",
    "\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_GNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_GNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_GNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sets = ShuffleSplit(n_splits=5, test_size=.2, random_state=8)\n",
    "param_grid = {\n",
    "    'alpha': [0.25, 0.5, 1, 1.5, 2], \n",
    "    'fit_prior': [False, True]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=MultiNB,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=cv_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=8, test_size=0.2, train_size=None),\n",
       "             estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.25, 0.5, 1, 1.5, 2],\n",
       "                         'fit_prior': [False, True]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.25, 'fit_prior': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333334"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9583333333333334\n",
      "Accuracy Score of Test Set: 0.9333333333333333\n",
      "F1 Score of Test Set: 0.9333333333333333\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.89      0.89      0.89         9\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.tab.txt', delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'Y'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = diabetes.iloc[:, :-1]\n",
    "labels = diabetes['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler().fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2, random_state=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.5779036827195467\n",
      "Accuracy Score of Test Set: 0.011235955056179775\n",
      "F1 Score of Test Set: 0.011235955056179775\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          39       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.25      1.00      0.40         1\n",
      "          72       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         1\n",
      "          94       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         104       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         2\n",
      "         118       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         1\n",
      "         129       0.00      0.00      0.00         2\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "         150       0.00      0.00      0.00         3\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         1\n",
      "         167       0.00      0.00      0.00         1\n",
      "         170       0.00      0.00      0.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         182       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         1\n",
      "         190       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         1\n",
      "         197       0.00      0.00      0.00         2\n",
      "         202       0.00      0.00      0.00         2\n",
      "         214       0.00      0.00      0.00         1\n",
      "         217       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         2\n",
      "         233       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         2\n",
      "         245       0.00      0.00      0.00         0\n",
      "         249       0.00      0.00      0.00         1\n",
      "         252       0.00      0.00      0.00         1\n",
      "         257       0.00      0.00      0.00         1\n",
      "         258       0.00      0.00      0.00         0\n",
      "         259       0.00      0.00      0.00         1\n",
      "         262       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         0\n",
      "         268       0.00      0.00      0.00         1\n",
      "         273       0.00      0.00      0.00         1\n",
      "         275       0.00      0.00      0.00         1\n",
      "         276       0.00      0.00      0.00         1\n",
      "         308       0.00      0.00      0.00         1\n",
      "         310       0.00      0.00      0.00         2\n",
      "         346       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.01        89\n",
      "   macro avg       0.00      0.01      0.00        89\n",
      "weighted avg       0.00      0.01      0.00        89\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "GaussNB = GaussianNB()\n",
    "GaussNB.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, GaussNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_GNB = GaussNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_GNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_GNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_GNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def prepare_train_test(self, test_size=0.2, random_state=8):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    def MultinomialNB(self):\n",
    "        MultiNB = MultinomialNB()\n",
    "        MultiNB.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        print(f\"Accuracy Score of Training Set:  {accuracy_score(self.y_train, MultiNB.predict(self.X_train))}\")\n",
    "\n",
    "        y_pred_MNB = MultiNB.predict(self.X_test)\n",
    "        print(f\"Accuracy Score of Test Set: {accuracy_score(self.y_test, y_pred_MNB)}\")\n",
    "\n",
    "        f1 = f1_score(self.y_test, y_pred_MNB, average='weighted')\n",
    "        print(f\"F1 Score of Test Set: {f1}\")\n",
    "\n",
    "        print(\"Classification Report\")    \n",
    "        print(classification_report(self.y_test, y_pred_MNB))\n",
    "        \n",
    "    def GaussianNB(self):\n",
    "        GaussNB = GaussianNB()\n",
    "        GaussNB.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(f\"Accuracy Score of Training Set:  {accuracy_score(self.y_train, GaussNB.predict(self.X_train))}\")\n",
    "\n",
    "        y_pred_GNB = GaussNB.predict(self.X_test)\n",
    "        print(f\"Accuracy Score of Test Set: {accuracy_score(self.y_test, y_pred_GNB)}\")\n",
    "\n",
    "        f1 = f1_score(self.y_test, y_pred_GNB, average='micro')\n",
    "        print(f\"F1 Score of Test Set: {f1}\")\n",
    "\n",
    "        print(\"Classification Report\")    \n",
    "        print(classification_report(self.y_test, y_pred_GNB))\n",
    "        \n",
    "    def BernoulliNB(self):\n",
    "        BernNB = BernoulliNB()\n",
    "        BernNB.fit(self.X_train, self.y_train)\n",
    "        print(f\"Accuracy Score of Training Set:  {accuracy_score(self.y_train, BernNB.predict(self.X_train))}\")\n",
    "\n",
    "        y_pred_BNB = BernNB.predict(self.X_test)\n",
    "        print(f\"Accuracy Score of Test Set: {accuracy_score(self.y_test, y_pred_BNB)}\")\n",
    "\n",
    "        f1 = f1_score(self.y_test, y_pred_BNB, average='micro')\n",
    "        print(f\"F1 Score of Test Set: {f1}\")\n",
    "\n",
    "        print(\"Classification Report\")    \n",
    "        print(classification_report(self.y_test, y_pred_BNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbObj = NaiveBayes(X_scaled, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbObj.prepare_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation Request:\n",
      "   This breast cancer databases was obtained from the University of Wisconsin\n",
      "   Hospitals, Madison from Dr. William H. Wolberg.  If you publish results\n",
      "   when using this database, then please include this information in your\n",
      "   acknowledgements.  Also, please cite one or more of:\n",
      "\n",
      "   1. O. L. Mangasarian and W. H. Wolberg: \"Cancer diagnosis via linear \n",
      "      programming\", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.\n",
      "\n",
      "   2. William H. Wolberg and O.L. Mangasarian: \"Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology\", \n",
      "      Proceedings of the National Academy of Sciences, U.S.A., Volume 87, \n",
      "      December 1990, pp 9193-9196.\n",
      "\n",
      "   3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: \"Pattern recognition \n",
      "      via linear programming: Theory and application to medical diagnosis\", \n",
      "      in: \"Large-scale numerical optimization\", Thomas F. Coleman and Yuying\n",
      "      Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.\n",
      "\n",
      "   4. K. P. Bennett & O. L. Mangasarian: \"Robust linear programming \n",
      "      discrimination of two linearly inseparable sets\", Optimization Methods\n",
      "      and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).\n",
      "\n",
      "1. Title: Wisconsin Breast Cancer Database (January 8, 1991)\n",
      "\n",
      "2. Sources:\n",
      "   -- Dr. WIlliam H. Wolberg (physician)\n",
      "      University of Wisconsin Hospitals\n",
      "      Madison, Wisconsin\n",
      "      USA\n",
      "   -- Donor: Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
      "      Received by David W. Aha (aha@cs.jhu.edu)\n",
      "   -- Date: 15 July 1992\n",
      "\n",
      "3. Past Usage:\n",
      "\n",
      "   Attributes 2 through 10 have been used to represent instances.\n",
      "   Each instance has one of 2 possible classes: benign or malignant.\n",
      "\n",
      "   1. Wolberg,~W.~H., \\& Mangasarian,~O.~L. (1990). Multisurface method of \n",
      "      pattern separation for medical diagnosis applied to breast cytology. In\n",
      "      {\\it Proceedings of the National Academy of Sciences}, {\\it 87},\n",
      "      9193--9196.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Collected classification results: 1 trial only\n",
      "      -- Two pairs of parallel hyperplanes were found to be consistent with\n",
      "         50% of the data\n",
      "         -- Accuracy on remaining 50% of dataset: 93.5%\n",
      "      -- Three pairs of parallel hyperplanes were found to be consistent with\n",
      "         67% of data\n",
      "         -- Accuracy on remaining 33% of dataset: 95.9%\n",
      "\n",
      "   2. Zhang,~J. (1992). Selecting typical instances in instance-based\n",
      "      learning.  In {\\it Proceedings of the Ninth International Machine\n",
      "      Learning Conference} (pp. 470--479).  Aberdeen, Scotland: Morgan\n",
      "      Kaufmann.\n",
      "      -- Size of data set: only 369 instances (at that point in time)\n",
      "      -- Applied 4 instance-based learning algorithms \n",
      "      -- Collected classification results averaged over 10 trials\n",
      "      -- Best accuracy result: \n",
      "         -- 1-nearest neighbor: 93.7%\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "      -- Also of interest:\n",
      "         -- Using only typical instances: 92.2% (storing only 23.1 instances)\n",
      "         -- trained on 200 instances, tested on the other 169\n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   Samples arrive periodically as Dr. Wolberg reports his clinical cases.\n",
      "   The database therefore reflects this chronological grouping of the data.\n",
      "   This grouping information appears immediately below, having been removed\n",
      "   from the data itself:\n",
      "\n",
      "     Group 1: 367 instances (January 1989)\n",
      "     Group 2:  70 instances (October 1989)\n",
      "     Group 3:  31 instances (February 1990)\n",
      "     Group 4:  17 instances (April 1990)\n",
      "     Group 5:  48 instances (August 1990)\n",
      "     Group 6:  49 instances (Updated January 1991)\n",
      "     Group 7:  31 instances (June 1991)\n",
      "     Group 8:  86 instances (November 1991)\n",
      "     -----------------------------------------\n",
      "     Total:   699 points (as of the donated datbase on 15 July 1992)\n",
      "\n",
      "   Note that the results summarized above in Past Usage refer to a dataset\n",
      "   of size 369, while Group 1 has only 367 instances.  This is because it\n",
      "   originally contained 369 instances; 2 were removed.  The following\n",
      "   statements summarizes changes to the original Group 1's set of data:\n",
      "\n",
      "   #####  Group 1 : 367 points: 200B 167M (January 1989)\n",
      "   #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\n",
      "   #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\n",
      "   #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\n",
      "   #####                  : Changed 0 to 1 in field 6 of sample 1219406\n",
      "   #####                  : Changed 0 to 1 in field 8 of following sample:\n",
      "   #####                  : 1182404,2,3,1,1,1,2,0,1,1,1\n",
      "\n",
      "5. Number of Instances: 699 (as of 15 July 1992)\n",
      "\n",
      "6. Number of Attributes: 10 plus the class attribute\n",
      "\n",
      "7. Attribute Information: (class attribute has been moved to last column)\n",
      "\n",
      "   #  Attribute                     Domain\n",
      "   -- -----------------------------------------\n",
      "   1. Sample code number            id number\n",
      "   2. Clump Thickness               1 - 10\n",
      "   3. Uniformity of Cell Size       1 - 10\n",
      "   4. Uniformity of Cell Shape      1 - 10\n",
      "   5. Marginal Adhesion             1 - 10\n",
      "   6. Single Epithelial Cell Size   1 - 10\n",
      "   7. Bare Nuclei                   1 - 10\n",
      "   8. Bland Chromatin               1 - 10\n",
      "   9. Normal Nucleoli               1 - 10\n",
      "  10. Mitoses                       1 - 10\n",
      "  11. Class:                        (2 for benign, 4 for malignant)\n",
      "\n",
      "8. Missing attribute values: 16\n",
      "\n",
      "   There are 16 instances in Groups 1 to 6 that contain a single missing \n",
      "   (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
      "\n",
      "9. Class distribution:\n",
      " \n",
      "   Benign: 458 (65.5%)\n",
      "   Malignant: 241 (34.5%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/breast-cancer-wisconsin.names\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/breast-cancer-wisconsin.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[data[6] != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1: -1]\n",
    "y = data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace(2, 0)\n",
    "y = y.replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "694    0\n",
       "695    0\n",
       "696    1\n",
       "697    1\n",
       "698    1\n",
       "Name: 10, Length: 683, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.prepare_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9542124542124543\n",
      "Accuracy Score of Test Set: 0.9854014598540146\n",
      "F1 Score of Test Set: 0.9854014598540146\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        84\n",
      "           1       0.98      0.98      0.98        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb.GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.8992673992673993\n",
      "Accuracy Score of Test Set: 0.927007299270073\n",
      "F1 Score of Test Set: 0.9260760130883463\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        84\n",
      "           1       0.96      0.85      0.90        53\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.91      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.6593406593406593\n",
      "Accuracy Score of Test Set: 0.6131386861313869\n",
      "F1 Score of Test Set: 0.6131386861313869\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        84\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.61       137\n",
      "   macro avg       0.31      0.50      0.38       137\n",
      "weighted avg       0.38      0.61      0.47       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "nb.BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9542124542124543\n",
      "Accuracy Score of Test Set: 0.9854014598540146\n",
      "F1 Score of Test Set: 0.9854014598540146\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        84\n",
      "           1       0.98      0.98      0.98        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GaussNB = GaussianNB()\n",
    "GaussNB.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, GaussNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_GNB = GaussNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_GNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_GNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "\n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_GNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sets = ShuffleSplit(n_splits=5, test_size=.2, random_state=8)\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=100)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=GaussNB,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='f1',\n",
    "                               cv=cv_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=8, test_size=0.2, train_size=None),\n",
       "             estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 0.15199110829529336}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Set:  0.9597069597069597\n",
      "Accuracy Score of Test Set: 0.9927007299270073\n",
      "F1 Score of Test Set: 0.9927007299270073\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        84\n",
      "           1       1.00      0.98      0.99        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestNB = grid_search.best_estimator_\n",
    "print(f\"Accuracy Score of Training Set:  {accuracy_score(y_train, bestNB.predict(X_train))}\")\n",
    "\n",
    "y_pred_bestNB = bestNB.predict(X_test)\n",
    "print(f\"Accuracy Score of Test Set: {accuracy_score(y_test, y_pred_bestNB)}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_bestNB, average='micro')\n",
    "print(f\"F1 Score of Test Set: {f1}\")\n",
    "      \n",
    "print(\"Classification Report\")    \n",
    "print(classification_report(y_test, y_pred_bestNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
